# 存储系统

+ 分类：![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/存储器分类_.jpg)
  + 对于按层次分类：<img src="https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/存储器分类.jpg" style="zoom:50%;" />
  + 直接存取：先随机到一个小区域，然后再这个小区域顺序存取——光盘
  
+ 存储器的性能指标：<img src="https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/存储器性能指标.jpg" style="zoom:50%;" />

+ 存储器的层次化结构：<img src="https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/存储器的层次化结构.jpg" style="zoom:50%;" />

  <img src="https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/存储层次结构.png" style="zoom:50%;" />

  + Cache通常会分层：L1、L2、L3

    + L1 Cache：数据缓存和指令缓存，距离CPU最近，几乎和寄存器一样快，只需要两到四个时钟周期

      每个CPU核心都有一块属于自己的L1高速缓存

      指令和数据在L1分开存放

      ```bash
      cat /sys/devices/system/cpu/cpu0/cache/index0/size // L1 Cache数据缓存容量
      
      cat /sys/devices/system/cpu/cpu0/cache/index1/size // L1 Cache指令缓存容量
      ```

    + L2高速缓存：10到20个时钟周期

      每个CPU核心都有

      ```bash
      index2就是
      ```

    + L3高速缓存：20到60个时钟

      多个CPU核心共用index3

  + 硬盘：

    + SSD, Solid-state disk固态硬盘
    + HDD, Hard Disk Drive机械硬盘

+ （半导体）存储器（以后默认半导体存储器）结构：

  ![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/半导体存储芯片的基础结构.jpg)

  + 

  ![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/存储器结构.jpg)

+ 寻址方式：

  ![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/寻址方式.jpg)

## RAM

+ RAM Random Access Memory随机存储器

  1. 静态随机存储器Static Random Access Memory     ：利用触发器的双稳态——常用缓存Cache
  2. 动态随机存储器Dynamic Random Access Memory：利用电容的充放电——常用于主存/内存——SDRAM，同步动态随机存储器

  | SRAM                                                      | DRAM                                                         |
  | --------------------------------------------------------- | ------------------------------------------------------------ |
  | 利用触发器的双稳态存储信息                                | 利用电容的充放电存储信息                                     |
  | 非破坏性输出                                              | 破坏性输出<br>读：连接电容检测电流变化：读后需要重新充电     |
  | 不需要刷新，能保存稳态                                    | 需要刷新，电容上的电荷只能维持**2ms**                        |
  | 同时送行列地址（行列独立）<br/>行列地址是一维但二进制指示 | 分两次送行列地址（行列复用）<br/>行列复用是矩阵<br>地址线复用、线数减少一半 |
  | 运行速度快                                                | 运行速度慢                                                   |
  | 集成度低，6个逻辑元件                                     | 集成度高，1或3个逻辑元件                                     |
  | 发热量大，因为线多                                        | 发热量少                                                     |
  | 成本高，因元件多                                          | 成本低                                                       |
  | 常用于Cache                                               | 常用于主存<br>同步动态随机存储器SDRAM                        |

  > 关于行列独立和行列复用：独立可以一次输送得到地址，直接指向，但是复杂而且线多，所以有了行列复用

+ DRAM的刷新：存储器内部的过程，不需要CPU的控制

  + 刷新周期：一般为**2ms**

  + 刷新范围：以行为单位，每次刷新一行存储单元

    > 行列地址：减少选通线的数量
    >
    > +  如果存储单元一维排列，要$2^n$条线
    > + 如果存储单元二维排列，要$2^{\frac{n}{2}} + 2^{\frac{n}{2}} = 2^{\frac{n}{2} + 1}$条线

  + 如何刷新：有硬件支持，读出一行的信息后重新写入，占用一个读写周期（或者说存取周期）

  + 何时刷新：

    + 分散刷新：每次读写都刷新（但是与读未必有关系）

    > 只要在刷新周期内完成刷新即可，刷新周期较于读写周期比较大，要刷新的范围较于剩余的时间小

    + 集中刷新：在一个刷新周期中拿出一块时间统一刷新：访存**死区**：刷新过程中无法访问存储器
    + 异步刷新：把一个刷新周期内的刷新次数均匀的分布在整个周期中

    ![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/DRAM的刷新.jpg)

+ SRAM的读写周期

  + 读周期：<img src="https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/SRAM读周期.jpg" style="zoom:60%;" />
  + 写周期：<img src="https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/SRAM写周期.jpg" style="zoom:60%;" />

  1. 从地址输入——到译码器接收口的时间
  2. 从译码器输出——到存储单元的时间
  3. 存储单元完全输出的时间（这是CS关了）
  4. 外界读取到有效存储单元输出的时间（等信号稳定）

## ROM

> RAM是易失性存储器，掉电丢失，外部存储/辅存可以掉电不丢失，但是CPU从其中读取仍需指令
>
> 此时需要一个既能掉电不丢失，又能为CPU提供指令

+ ROM只读存储器Read-Only Memory：空间不大，作为CPU和辅存的连接，比如指出操作系统在那里
+ 分类/发展历程：
  1. 掩膜式只读存储器MROM       ：存储内容由半导体制造厂使用用户提出的要求在芯片的生产过程中直接写入，无法修改。
  2. 一次可编程只读存储器PROM：存储内容由用户用专门的设备（编程器）一次性写入，之后无法修改。
  3. 可擦除可编程只读存储器EPROM：紫外线擦除UVEPROM/电擦除EEPROM；修改次数有限，写入时间很长。
  4. 闪速存储器Flash Memory  ：如U盘，写入速度较快（但慢于RAM）
  5. 固态硬盘Solid State Drives：控制单元+FLASH芯片。
+ 特点：结构简单，位密度比RAM高，非易失性，可靠性高

## 和CPU连接

+ 存储器扩展：

  1. 位扩展：

     + 地址不变：WE不变CS接一，多个D分别接

  2. 字扩展：

     + 地址不变：WE不变，D对应接，高位地址控制CS

       > 关于CS
       >
       > + 线选法：分别对应接地址，多的线一一对应，电路简单，地址空间不连续，，有浪费
       > + 译码片选法：一个高维地址，通过一个取反接两个，再多就通过译码器，地址空间连续，可增加逻辑设计

+ 系统程序区用ROM，用户程序区用RAM

+ 题目：

  1. 选择合适的存储器：类型、空间、字长

## 特殊接口

> 由摩尔定律，CPU的速度和存储器的空间都是指数增长，但是读取速度不是，所以计算机的速度在被读写速度限制

### 双口RAM

![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/双端口RAM.jpg)

### 多模块存储器

> ![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/多模块存储器.jpg)
>
> 主要讨论多体并行存储器

+ 分类：如图，这里编址方式从小到大，所以左边的竖着看，右边的横着看

  ![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/多体并行存储器分类.jpg)

  + 低位交叉编址的多体存储器如果总线宽度是`m * 字长`，则可以同时取出一大行数据

+ 影响：大多寻址方式都是由小到大一次寻址，所以在寻址起来时空上就有所不同：

  ![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/多体并行存储器存储不同.jpg)

  1. 高位：存储体一个一个使用，两个存储周期不能交叉
  2. 低位：需要因为流水线的概念讨论

+ 流水线：

  有存储器的存储周期`T`（从启动存取到存取完再到恢复可再此存取的时间）、时间$\tau$（启动一个存储器的时间）、`m`（存储器数）

  前一个存取花费前一个存储器的T，经过$\tau$时间即可在下一个存储器开始存取：$连续存取n个字耗时=T + (n - 1) \tau \ \ \ m \equiv \frac{T}{\tau}$

  + 具体讨论情况如下：<img src="https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/流水线tau.jpg" style="zoom:60%;">
  + 再看：$带宽 = \frac{n \times W}{T + (n - 1)\tau}$：当n较大时$n \backsim n - 1, T << (n - 1)\tau \rightarrow 带宽$

## Cache

+ 多级Cache：里CPU越远越慢，容量越大

![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/Cache.jpg)

<img src="https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/Cache分层体系.png" style="zoom:50%;" />

+ CPU Cache的数据是从内存中读取过来的，是一小块一小块的读，即Cache Line缓存块

  ```c++
  cat /sys/devices/system/cpcu/cpu0/cache/index0/coherency_line_size
  ```

+ CPU的分支预测器：对于ifelse，说明至少有两组指令，如果cpu可以预测条件的结果，则可以直接跳转过去

  > 这里的指的是Cache L1有数据缓存和指令缓存，这里就是指令缓存，把指令放在缓存中

  ```c++
  #define likely(x) __builtin_expect(!!(x), 1)
  #define unlikely(x) __builtin_expect(!!(x), 0)
  
  if (likely(表达式)) {}  // 如果程序员知道就是大概率true，用这种方式可以加快速度
  else {}
  ```



+ 在多核CPU中，我们发现多进程切换的话，一个cpu对一个进程所缓存的信息可能白缓存了（这个进程去另一个cpu），可以把线程绑定在某一个cpu核心上，

  ```c++
  #define _GNU_SOURCE
  #include <sched.h>
  
  int sched_setaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask);
  ```

  

### 引入和分析

+ 局部性原理：

  > MDR和MAR虽然是存储器的部分，但是和CPU更近，多直接将它们放在CPU中和主存通信

  + 空间局部性：在最近的将来要用的信息（指令和数据），很可能和现在正使用的信息在存储空间上邻近。
  + 时间局部性：在最近的将来要用的信息（指令和数据），很可能是现在正是用的信息。

+ 性能分析：

  + 定义：
    + 命中率`H`：CPU要访问的信息已在Cache中的比率：$H = \frac{Cache的总命中次数N_c}{N_c + 访问主存的总次数N_m}$
    + 缺失率：$M = 1 - H$
  + 规定：$t_c$命中时Cache的访问时间，$t_m$未命中时的访问问时间

  平均访问时间：$\overline{t} = Ht_c + (1-H)t_m$

  + 设每个周期可存取的数据量为$S$

  1. 若同时访问主存和Cache：则使用Cache的系统带宽$\frac{S}{\overline{t}}$，不使用则系统带宽$\frac{S}{不命中的时间——t_m}$，**性能**两者之比
  2. 若先访问Cache再访问主存：则$t_m \rightarrow t_c + t_m$：先试试行不行，不行再主存，后续计算对应改变

  + **系统效率**$\frac{Cache的存储周期}{平均访问时间\overline{t}}$

### 地址映射

![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/Cache地址映射.jpg)

+ 总览：![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/地址映射.jpg)

1. 全相联映射Fully Associative Cache：

   + 如何判断哪些块已经放过东西：有效位（0没放，1有放）
   + 如果确定这些块内信息源地址：在Cache行前指出

   ![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/地址映射1.jpg)

2. 直接映射Direct Mapped Cache：主存中的某一块通过某种算法（行号取余）送到特定一块

   + 仍有冲突，故还需要指明地址，又按行取模（分组），故可省略部分

   ![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/地址映射2.jpg)

   > 普通的直接映射是多个内存中的地址对应Cache中的一个地址，需要有办法区分，而且还有就是关于数据的读写问题
   >
   > 还有就是一个Cache Line的大小可能大于CPU的字长，就是我们不需要一个Cache Line中的全部信息，这就需要一个偏移量

   + 一个访问的地址需要有：组标记、CPU Line索引、偏移量
   + Cache里的数据结构有：索引、有效位、组标记、数据块

   1. 通过索引计算地址
   2. 去到cache对应位置，看有效位看这个位置是否被读写
      1. 有效：往下
      2. 无效，去内存，重新加载
   3. 对比组标记，看是不是我们要的对应的内存的
      1. 不是：去内存，重新加载
      2. 有效：往下
   4. 通过偏移量加载字

3. 组相联Set Associative Cache：

   ![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/地址映射3.jpg)

### 替换算法

+ 替换算法：![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/替换算法.jpg)
  + 随机算法不常用不常考

+ LRU可以这样想象：有个序列，未命中，放在序列头（挤出序列尾），如果命中，将其拿出来（拼接序列），然后把它放在序列头

+ 具体问题具体分析：

  1. 全相联映射：使用2、3、4算法，
     + **相联存储器**（并行比较标记，若有标记与将要访问的地址的标记相同，且有效位为1，则命中）：相联存储器是按内容指定方式进行寻址的存储器
     + 对于3、4算法顶替第一个不符合条件的
  2. 直接映射没有所谓的替换策略：做题时对块数取余
  3. 组在组内使用2、3、4策略              对组数取余

  + ![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/替换算法做题1.jpg)
    + LRU也是向上抬

### 写策略

> 在Cache中命中，读无所谓，但是如果想写入，Cache和内存又不一样

修改Cache后，如何保持和主存中相应内容的一致性

+ 命中：

  + 写回法（write-back）：新的数据仅仅写回Cache Block，只有其被替换时才写到内存，

    通过一个标记位，脏Dirty标记

    ![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/写策略-命中-写回法.jpg)

  + 全写法/写直达（weite-through）：即写回Cache、又写回内存![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/写策略-命中-全写法.jpg)
    + 写缓冲可能溢出

+ 不命中：

  + 写分配法（write-allocate）：把未命中的的块移入Cache，然后按命中搞

    ![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/写策略-不命中-写分配法.jpg)

  + 非写分配法（not-write-allocate）：直接修改

    !![](https://cdn.jsdelivr.net/gh/zweix123/CS-notes-img@master/Computer-Organization&Architecture/写策略-命中-非全写法.jpg)

+ 写回法和写分配法搭配，要添加多一个位数

+ 全写法和非写分配法，不同添加，还能保持一致性，但是有溢出的风险

+ Cache容量的计算：每个块的大小 * 块的数量 + 标记位（通过主存和Cache相对大小计算） * 数量
  + 标记位：
    + 有效位：有无存东西
    + 标记位：相对计算——和主存的关系：地址映射
    + 一致性维护位：（副本）和主存中是否一样：写策略决定
    + 替换算法位：和替换策略有关

#### 多核

+ 缓存一致性Cache Coherence

  我们发现Cache的L1和L2缓存都是单核的，那么如果两个核的Cache都缓存了一个变量，其中一个修改了Cache，有时可能这个没有写回内存，这时另一个CPU如果用它的Cache中的这个信息就是错的

  1. 写传播Wreite Propagation：某个CPU核心Cache数据更新，必须传播到其他核心的Cache

  2. 事务串形化Transaction Serialization：每个CPU核心里对数据的操作顺序必须在其他核心看起来顺序是一样的

     > 这里指的是，比如多个指令修改同一个变量，那么每个核心的Cache的变化顺序都是一样的

+ 总线嗅探Bus Snooping：通过在总线上广播，但是这个会加重总线的负载，而且不能实现事务串行化

+ MESI协议：

  + Modified已修改：即脏标记
  + Exclusive独占：可以，恰好只有这一个cpu有，那么使用时不需要广播
  + Shared共享：可以：先广播在修改（等其他改为失效）
  + Invalidated已失效：即被其他的cpu修改

  可以用状态机表示
  
  + 这里的状态标记的是Cache Line，而一个Cache Line里面可能有多个变量
  
    > 这里，如果两个cpu对相邻变量，然后分别处理一个，这时两个读写虽然没有冲突，但是由于在一个，所以就会返回修改状态
  
    ```c
    #ifdef CONFIG_SMP
    #define __cacheline_aligned_in_smp __cacheline_aligned
    #else
    #define __cacheline_aligned_in_smp
    #endif
    ```
  
    在多核系统中，这个宏定义的值是Cache Line的大小，单核系统是空
  
    ```c
    struct test {
        int a;
        int b __cacheline_aligned_in_smp;
    }
    ```
  
    这样两个变量在两个Cache中，空间换时间

## 虚拟存储器

> 矛盾还是CPU快，但是和内存的交流慢
>
> + 多模块是提高存储器的工作速度
> + Cache高速缓冲存储器是提高存储气筒的工作速度
> + 还有其他思路吗？
>   + 提高存储系统容量



+ 本质就是使劲分层：距离CPU越近越快，容量越小，

  cpu cache 	主存 辅存      云端

+ 虚拟存储器是一个逻辑模型：

  + 功能：用户给出一个地址，叫做虚地址或逻辑地址，虚拟存储器要给出该地址对应的数据
  + 实现：由辅助硬件将虚地址映射到主存当中的某个单元，主存单元地址成为实物地址或物理地址

+ 单位：下面的表都在内存，读写还要时间（慢表page（如果放Cache就是快表TLB））

  + 页：划分成相同的页，主存是实页，虚存是虚页；；；页内地址一一映射，关键在两个页号的映射
    + 有个页表：使用页表基址寄存器，含有页表起始地址，然后结合虚页号找到页表中的位置（顺序线性表）就找到了
  + 段：把上面的页换成段，就是实地址没有段，，可以通过段和段表虚地址的段内地址一个异或就是主存地址
  + 段页式虚拟存储器：
