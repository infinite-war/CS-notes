+ Pre: 怎么存储一个巨大的文件呢？一个很自然的想法，sharding，这时就要面对那个经典问题，在大数定理下，机器多了出现错误几乎是必然的，怎么fault tolerance呢？又一个自然的想法是replication，有了副本，就要面对consistency问题，为了解决一致性问题，机器间就要有额外的网络交互，即一致性的代价是低性能，这里需要平衡。  
	一致性还有一个含义：对用户来说，多个机器看起来就像一个机器。这带来一个问题，对用户来说多机器是向一个机器、反过来一个机器要面对多个用户的访问。这会带来什么问题呢？比如多个用户对同一个“用户视角下的同一个文件”进行写，但是机器间为了一致性而通信，如何这些消息到不同机器的顺序不一样怎么办？

>GFS发表于SOSP，这是一个更注重创新的会议，而GFS提到一致性算法基本都被讨论过，而GFS的特点是规模非常大、非常工业级（而不是学术界），即使是弱一致性。

+ 我们希望GFS有的特性
	+ 全局通用（一种通用存储）
	+ sharding
	+ automatic recovery
+ GFS在实现过程中不可避免出现的特性：
	+ GFS机器们在同一个数据中心中（实际上应该分布的更远一些）
	+ Google内部使用
	+ 适用于巨大文件，建议顺序处理（而不是随机），关于点在大吞吐量

## Implementation


### Master
是Active-Standby模式的

存储文件名和存储位置的对应关系


大量的chunk服务器（每个服务器1到2个desk）


master管理文件和chunk
chunk存储实际数据



master中的一个
一个表：文件名到chunk ID——————————non-volatile, 非易失，保存到硬盘
另一个表：文件名chunk id到chuck data strcur

这个数据
+ 每个chunk存储在那个服务器，一个列表————————这个不保存到硬盘，如果重启则重新通信V（volatile
+ 每个chunk版本号——取决于实现
+ 主chunk，Primary Chunk，因为写要在primary chunk上进行
+ 而每个主chunk只在租约时间内担任主

这些信息保存在内存，定期到硬盘——追加log，生成CheckPoint————————————快照


主chunk不保存，这玩意本来就动态的